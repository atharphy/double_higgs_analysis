{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97594700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from array import array\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import collections\n",
    "import uproot\n",
    "import ROOT\n",
    "import sys\n",
    "from os import environ, path, mkdir, listdir\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import h5py\n",
    "environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "def getGuess(df, index):\n",
    "    try:\n",
    "        prob_sig = df.loc[index, 'prob_sig']\n",
    "    except:\n",
    "        prob_sig = -999\n",
    "    return prob_sig\n",
    "\n",
    "def build_filelist(input_dir):\n",
    "    filelist = collections.defaultdict(list)\n",
    "    filelist['all'] = [fname for fname in glob('{}/*.csv'.format(input_dir))]\n",
    "    return filelist\n",
    "\n",
    "model = load_model('/localdata/Athar/models/{}.hdf5'\n",
    "                   .format('model_name'))\n",
    "all_data = pd.HDFStore('/localdata/Athar/datasets/preprocessed_dataset.h5.h5') \n",
    "if not path.isdir('/localdata/Athar/output_files'):\n",
    "    mkdir('/localdata/Athar/output_files')\n",
    "\n",
    "filelist = build_filelist('/localdata/Athar/input_files')\n",
    "for _, files in filelist.items():\n",
    "    for ifile in files:\n",
    "        print ('Processing file: {}'.format(ifile))\n",
    "        fname = ifile\n",
    "        MakeCsvDataFrame = ROOT.RDF.MakeCsvDataFrame\n",
    "        csv_file = MakeCsvDataFrame(ifile)\n",
    "        input_dict = csv_file.AsNumpy()\n",
    "        output_file = pd.DataFrame.from_dict(input_dict)\n",
    "        data = all_data['nominal']\n",
    "        print('Sample' + fname)\n",
    "        sample = data[(data['sample_names'] == fname)]\n",
    "        to_classify = sample[['pxB1', 'pyB1', 'pzB1', 'eB1', 'pxB2', 'pyB2', 'pzB2', 'eB2', 'pxJ1', 'pyJ1', 'pzJ1', 'eJ1',\n",
    "              'pxJ2', 'pyJ2', 'pzJ2', 'eJ2', 'pxL1', 'pyL1', 'pzL1', 'eL1', 'pxN1', 'pyN1', 'pzN1', 'eN1',\n",
    "              'pxH', 'pyH', 'pzH', 'eH', 'pxt11', 'pyt11', 'pzt11', 'et11', 'pxt12', 'pyt12', 'pzt12',\n",
    "              'et12', 'pxt21', 'pyt21', 'pzt21', 'et21', 'pxt22', 'pyt22', 'pzt22', 'et22', 'pxW1', 'pyW1', \n",
    "              'pzW1', 'eW1', 'pxW2', 'pyW2', 'pzW2', 'eW2', 'm_B1', 'pt_B1', 'eta_B1', 'phi_B1', 'm_B2', \n",
    "              'pt_B2', 'eta_B2', 'phi_B2', 'm_J1', 'pt_J1', 'eta_J1', 'phi_J1', 'm_J2', 'pt_J2', 'eta_J2', \n",
    "              'phi_J2', 'm_L1', 'pt_L1', 'eta_L1', 'phi_L1', 'm_N1', 'pt_N1', 'eta_N1', 'phi_N1', 'm_H', \n",
    "              'pt_H', 'eta_H', 'phi_H', 'm_t11', 'pt_t11', 'eta_t11', 'phi_t11', 'm_t12', 'pt_t12', \n",
    "              'eta_t12', 'phi_t12', 'm_t21', 'pt_t21', 'eta_t21', 'phi_t21', 'm_t22', 'pt_t22', 'eta_t22', \n",
    "              'phi_t22', 'm_W1', 'pt_W1', 'eta_W1', 'phi_W1', 'm_W2', 'pt_W2', 'eta_W2', 'phi_W2'\n",
    "             ]]\n",
    "        \n",
    "        print(to_classify.shape)\n",
    "        guesses = model.predict(to_classify.values, verbose=True)\n",
    "        out = data.copy()\n",
    "        output_file['prob_sig'] = guesses[:,0]\n",
    "        print(output_file)\n",
    "        out_name = ifile.split('/')[-1].replace('.csv', '_classified.csv')\n",
    "        output_file.to_csv('/localdata/Athar/output_files/{}'.format(out_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
